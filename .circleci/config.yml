
version: 2.1

jobs:
  
  integration-postgres:
    docker:
      - image: cimg/python:3.9
      - image: cimg/postgres:9.6
        environment:
          POSTGRES_USER: root
    environment:
      POSTGRES_HOST: localhost
      POSTGRES_USER: root
      DBT_ENV_SECRET_POSTGRES_PASS: ''
      POSTGRES_PORT: 5432
      POSTGRES_DATABASE: circle_test
      POSTGRES_SCHEMA: dbt_utils_integration_tests_postgres

    steps:
      - checkout
      - run: pip install --pre dbt-postgres -r dev-requirements.txt
      - run:
          name: "Run OG Tests - Postgres"
          command: ./run_test.sh postgres
      - store_artifacts:
          path: integration_tests/logs
      - store_artifacts:
          path: integration_tests/target

    # The resource_class feature allows configuring CPU and RAM resources for each job. Different resource classes are available for different executors. https://circleci.com/docs/2.0/configuration-reference/#resourceclass    
    resource_class: large

  integration-redshift:
    docker:
      - image: cimg/python:3.9
    steps:
      - checkout
      - run: pip install --pre dbt-redshift -r dev-requirements.txt
      - run:
          name: "Run OG Tests - Redshift"
          command: ./run_test.sh redshift
      - store_artifacts:
          path: integration_tests/logs
      - store_artifacts:
          path: integration_tests/target
    # The resource_class feature allows configuring CPU and RAM resources for each job. Different resource classes are available for different executors. https://circleci.com/docs/2.0/configuration-reference/#resourceclass    
    resource_class: large

  integration-snowflake:
    docker:
      - image: cimg/python:3.9
    steps:
      - checkout
      - run: pip install --pre dbt-snowflake -r dev-requirements.txt
      - run:
          name: "Run OG Tests - Snowflake"
          command: ./run_test.sh snowflake
      - store_artifacts:
          path: integration_tests/logs          
      - store_artifacts:
          path: integration_tests/target
    # The resource_class feature allows configuring CPU and RAM resources for each job. Different resource classes are available for different executors. https://circleci.com/docs/2.0/configuration-reference/#resourceclass    
    resource_class: large

  integration-bigquery:
    environment:
      BIGQUERY_SERVICE_KEY_PATH: "/home/circleci/bigquery-service-key.json"
    docker:
      - image: cimg/python:3.9
    steps:
      - checkout
      - run: pip install --pre dbt-bigquery -r dev-requirements.txt
      - run:
          name: Setup Environment Variables
          command: echo 'export BIGQUERY_KEYFILE_JSON="$BIGQUERY_SERVICE_ACCOUNT_JSON"' >> "$BASH_ENV"
      - run:
          name: "Run OG Tests - BigQuery"
          command: ./run_test.sh bigquery
      - store_artifacts:
          path: integration_tests/logs
      - store_artifacts:
          path: integration_tests/target
    # The resource_class feature allows configuring CPU and RAM resources for each job. Different resource classes are available for different executors. https://circleci.com/docs/2.0/configuration-reference/#resourceclass    
    resource_class: large

workflows:
  version: 2
  test-all:
    jobs:
      - integration-postgres:
          context: profile-postgres
      - integration-redshift:
          context: profile-redshift
          requires:
            - integration-postgres
      - integration-snowflake:
          context: profile-snowflake
          requires:
            - integration-postgres
      - integration-bigquery:
          context: profile-bigquery
          requires:
            - integration-postgres
